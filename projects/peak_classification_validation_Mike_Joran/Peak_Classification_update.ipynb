{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation of the classification based on the WFsim #\n",
    "\n",
    "2019/09/28\n",
    "\n",
    "Authors:\n",
    " - Clark, Michael <clark632@purdue.edu>\n",
    " - Angevaare, Joran <j.angevaare@nikhef.nl>\n",
    " \n",
    "**Updates:**\n",
    "\n",
    "2019/11/14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook #\n",
    " \n",
    " \n",
    "Possible extensions:\n",
    " - Add afterpulse boolian to the 'truth' info\n",
    " - Do the same for the other detector types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import strax\n",
    "import straxen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We include ``recarray_tools.py`` here that is used to add columns and do things with structured arrays. \n",
    "Taken from:\n",
    "\n",
    "    https://github.com/XENON1T/XeAnalysisScripts/tree/master/PeakFinderTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peak_classification.recarray_tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peak_classification.wfsim_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peak_classification.match_peaks import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initize the wavefrom simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions_csv = \"./test_uni.csv\"\n",
    "instructions = dict(event_rate = 100 , chunk_size=10, nchunk=5)\n",
    "inst_to_csv(instructions, instructions_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = strax.Context(\n",
    "    register=[wfsim.RawRecordsFromFax],\n",
    "    config=dict(fax_file=instructions_csv),\n",
    "    **straxen.contexts.common_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPeakClassification(strax.Plugin):\n",
    "    # Name of the data type this plugin provides\n",
    "    provides = 'peak_classification'\n",
    "    \n",
    "    # Data types this plugin requires. Note we don't specify\n",
    "    # what plugins should produce them: maybe the default PeakBasics\n",
    "    # has been replaced by another AdvancedExpertBlabla plugin?\n",
    "    depends_on = ('peak_basics')\n",
    "    \n",
    "    # Numpy datatype of the output \n",
    "    dtype = straxen.PeakClassification.dtype\n",
    "    \n",
    "    # Version of the plugin. Increment this if you change the algorithm.\n",
    "    __version__ = '0.0.1'\n",
    "    \n",
    "    result = {}\n",
    "    def compute(self, peaks):\n",
    "        result = np.zeros(len(peaks), dtype=self.dtype)\n",
    "        masks1 = (peaks['n_channels']>2) & (peaks['range_50p_area'] < 100)\n",
    "        \n",
    "        result['type'][masks1] = 1\n",
    "        masks2 = (peaks['n_channels']>2) & (peaks['area'] > 20) & (peaks['range_50p_area'] > 100)\n",
    "        result['type'][masks2] = 2\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just some id from post-SR1, so the corrections work\n",
    "run_id = '180519_1902'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data found in 'strax_data', press [y] to remove and create new data\n",
      "y\n",
      "deleted data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulating Raw Records:   6%|â–‹         | 634/10000 [00:36<23:31,  6.64it/s]"
     ]
    }
   ],
   "source": [
    "if check_for_strax_data():\n",
    "    !rm -r strax_data/\n",
    "    print('deleted data')\n",
    "\n",
    "peaks = st.make(run_id, 'raw_records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = st.get_array(run_id, 'truth')\n",
    "data_default = st.get_array(run_id, ['peak_basics','peak_classification'])\n",
    "data_custom = st.get_array(run_id, ['peak_basics','peak_classification'],\n",
    "                          register=CustomPeakClassification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to compensate for the fact that we dont have event numbers (Binning in time to group peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_grid = get_timing_grid(instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Proxy for event number\n",
    "truth = append_fields(truth, 'merge_index',np.digitize(truth['t'], timing_grid))\n",
    "data_default = append_fields(data_default, 'merge_index', \n",
    "                             np.digitize(data_strax['time'], timing_grid))\n",
    "data_custom = append_fields(data_custom, 'merge_index', \n",
    "                            np.digitize(data_strax['time'], timing_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There is a bug that the types are listed here as strings, where in strax they are integers**\n",
    "The code here is to change that such that we can compare them directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proxy for ``left`` and ``right`` (as in ``PAX``) sides of peak in truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Proxy for left and right of peak\n",
    "truth = append_fields(truth, \n",
    "                      ('time','endtime'), \n",
    "                      (truth['t_first_photon'],\n",
    "                       truth['t_last_photon']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here in match_peaks.py, written by Jelle, to compare two sets of peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call with (truth, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thruth_vs_default, default_vs_truth = match_peaks(truth,data_default)\n",
    "thruth_vs_custom, custom_vs_truth = match_peaks(truth,data_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the output of match_peaks for the truth data.  \n",
    "  - For each peak, **outcome** shows whether the peak was found, missed, merged, split up, or misidentified in the output of strax for the simulated data\n",
    "  - **matched_to** shows which peak (peak_id in the other array) it was matched with, or the biggest peak it was matched with \n",
    "\n",
    "<img src='toptruthmatches.png'>\n",
    "  \n",
    "Below is the corresponding match_index in the simulated data\n",
    "<img src='topdatamatch.png'>\n",
    "  \n",
    "You can see the splitting of the true s2 into an s1 and an s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['merge_index','type','time','n_photon','endtime','matched_to','outcome']\n",
    "pd.DataFrame.from_records(thruth_vs_default[headers])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headers = ['merge_index','type','time','area','endtime','matched_to','outcome']\n",
    "# pd.DataFrame.from_records(datamatched[headers]).head(10)\n",
    "# #pd.DataFrame.from_records(truthmatched[['merge_index','type','time','area','endtime','matched_to','outcome']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headers = ['merge_index','type','time','n_photon','endtime','matched_to','outcome']\n",
    "# pd.DataFrame.from_records(truthmatched[truthmatched['outcome'] == b'found'][headers])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the results ##\n",
    "The plots below show the fraction of several of the ``dtypes`` of the ``truth`` or the ``data``. These fractions show how many of the ``peaks`` were found correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default ``strax`` options, first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_peak_matching_histogram(thruth_vs_default,'type',bins=[-0.5,0.5,1.5,2.5])\n",
    "plt.xlabel('Peak Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The custom options as introduced above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_peak_matching_histogram(thruth_vs_custom,'type',bins=[-0.5,0.5,1.5,2.5])\n",
    "plt.xlabel('Peak Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "state": {
    "a26e7f9ab967429687376a4127408b3b": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
